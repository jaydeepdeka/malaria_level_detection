{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASE MODEL TO DETECT PARASITES and NON_PARASITES\n",
    "\n",
    "The data set is downloaded from [kaggle](https://www.kaggle.com/iarunava/cell-images-for-detecting-malaria).\n",
    "The target dataset is heavily imbalanced, hence we are trying to build a base model which has already learnt the basic features from a similar kind of dataset and can be used in the later with limited data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required modules\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torchvision\n",
    "import copy\n",
    "from copy import copy\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "# from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "torch.cuda.current_device() # Work around for the Bug https://github.com/pytorch/pytorch/issues/20635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\ADM_project\\cell_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(50),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, dataset_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining dataloaders which is used in creating subsets\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=16,\n",
    "                                             shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a pre-trained model we are considering VGG-16 with the pre-trained weights on ImageNet\n",
    "model_vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# Cancelling gradient descent calculation for all the layers\n",
    "for param in model_vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Activating last two Convolutional layers of the network\n",
    "len_features = len(model_vgg16.features)\n",
    "for i in range(len_features-5, len_features):\n",
    "    model_vgg16.features[i].requires_grad = True\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_vgg16.classifier[0].in_features\n",
    "model_vgg16.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512), \n",
    "    nn.ReLU(), \n",
    "    nn.Dropout(p=0.2), \n",
    "    nn.Linear(512, 2)\n",
    ")\n",
    "\n",
    "# Loading the device to CUDA\n",
    "model_vgg16.to(device)\n",
    "\n",
    "# Loss Function definition\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Using Adam as the optimizer for the feature network\n",
    "optimizer_feature = optim.Adam(model_vgg16.features.parameters(), lr=0.001)\n",
    "# Using Stochastic Gradient Descent as the optimizer for the classifier network\n",
    "optimizer_classifier = optim.SGD(model_vgg16.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_classifier, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer_fe, optimizer_cl, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataset_loader:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer_fe.zero_grad()\n",
    "                optimizer_cl.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer_fe.step()\n",
    "                    optimizer_cl.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "#                 print(preds==labels.data)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            print(\"Running Corrects: \", running_corrects)\n",
    "            print(\"Dataset Size: \", len(dataset))\n",
    "            epoch_loss = running_loss / len(dataset)\n",
    "            epoch_acc = running_corrects.item() / len(dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "Running Corrects:  tensor(1472, device='cuda:0')\n",
      "Dataset Size:  1800\n",
      "train Loss: 0.4115 Acc: 0.8178\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "Running Corrects:  tensor(1470, device='cuda:0')\n",
      "Dataset Size:  1800\n",
      "train Loss: 0.4012 Acc: 0.8167\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "Running Corrects:  tensor(1494, device='cuda:0')\n",
      "Dataset Size:  1800\n",
      "train Loss: 0.3620 Acc: 0.8300\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "Running Corrects:  tensor(1536, device='cuda:0')\n",
      "Dataset Size:  1800\n",
      "train Loss: 0.3356 Acc: 0.8533\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "Running Corrects:  tensor(1519, device='cuda:0')\n",
      "Dataset Size:  1800\n",
      "train Loss: 0.3506 Acc: 0.8439\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "Running Corrects:  tensor(1517, device='cuda:0')\n",
      "Dataset Size:  1800\n",
      "train Loss: 0.3429 Acc: 0.8428\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "Running Corrects:  tensor(1526, device='cuda:0')\n",
      "Dataset Size:  1800\n",
      "train Loss: 0.3464 Acc: 0.8478\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "Running Corrects:  tensor(1529, device='cuda:0')\n",
      "Dataset Size:  1800\n",
      "train Loss: 0.3418 Acc: 0.8494\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "Running Corrects:  tensor(1526, device='cuda:0')\n",
      "Dataset Size:  1800\n",
      "train Loss: 0.3513 Acc: 0.8478\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "Running Corrects:  tensor(1517, device='cuda:0')\n",
      "Dataset Size:  1800\n",
      "train Loss: 0.3403 Acc: 0.8428\n",
      "\n",
      "Training complete in 5m 16s\n",
      "Best val Acc: 0.000000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_vgg16, criterion, optimizer_feature, optimizer_classifier, exp_lr_scheduler,\n",
    "                       num_epochs=10)\n",
    "# Free up Cached memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu_pytorch)",
   "language": "python",
   "name": "gpu_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
